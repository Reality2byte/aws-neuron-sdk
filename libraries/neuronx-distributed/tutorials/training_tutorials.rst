.. _nxd_training_tutorials:

Training Tutorials
============================================================

.. toctree::
    :maxdepth: 1
    :hidden:
        
    Training using Tensor Parallelism </libraries/neuronx-distributed/tutorials/training>
    Training Llama 3.1 8B/Llama 3 8B using TP and ZeRO-1 </libraries/neuronx-distributed/tutorials/training_llama_tp_zero1>
    Training Llama 3.1 70B/Llama 3 70B using TP and PP </libraries/neuronx-distributed/tutorials/training_llama_tp_pp>
    Fine-tuning Llama3 8B with tensor parallelism and LoRA using Neuron PyTorch-Lightning </libraries/neuronx-distributed/tutorials/finetune_llama3_8b_ptl_lora>

.. include:: /libraries/neuronx-distributed/tutorials/nxd_training_tutorials.txt

